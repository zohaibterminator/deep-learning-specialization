In a NN, there can be multiple neurons or nodes, like we saw when discussing logistic regression, stacked on top of eeach other. In logistic regression, we saw that each node performed 2 operations, calculating z, then applying sigmoid function to calculate a. We will use a superscript on top of the parameters like this W^[1] and b^[1] to indicate the "layer" they are used in. These parameters will them be used to calculate z^[1]. This z^[1] will then be used to calculate a^[1]. When we write W^[2] and b^[2], we are referring to the parameters of layer 2. Just like in logistic regression, there was this backwards step to calculate derivatives, we will also do that here to calculate da^[2] and dz^[2] and da^[1] and dz^[1].