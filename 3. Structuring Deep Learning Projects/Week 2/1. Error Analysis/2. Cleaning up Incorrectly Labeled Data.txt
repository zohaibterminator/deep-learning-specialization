The data for your supervised learning problem comprises input X and output labels Y. What if you going through your data and you find that some of these output labels Y are incorrect, you have data which is incorrectly labeled? Is it worth your while to go in to fix up some of these labels?

Lets say you find some incorrectly labelled examples in your cat classification dataset, which some labeller accidently labelled. Now, DL algoriothms are quite robust when it comes to random errors in the training set. So, if your errors in labelling are not far from being random, it is probably okay to leave the errors as they are and not spend too much time fixing them if the actual percentage of the errors aren't too high. The caveat to this, is that the DL algorithms are robust to *random errors* in the training set. They are less robust to systemic errors in the training set. So, if the labeller has consistently labelled white dogs as cats, then that is a problem, because the algorithm will consistently label white dogs as cats.

How about the incorrectly labelled examples in the dev or test set? If you are worried about the impact of incorrect labels in the dev or test set, just set up an additional column for examples with incorrect labels during error analysis. If the incorrect label makes up of, lets say, 6% of the misclassified labels, then is it worthwhile going in to try to fix up this 6% of incorrectly labeled examples. My advice is, if it makes a significant difference to your ability to evaluate algorithms on your dev set, then go ahead and spend the time to fix incorrect labels. But if it doesn't make a significant difference to your ability to use the dev set to evaluate classifiers, then it might not be the best use of your time.

We will take the previous error analysis example, and again assume that the dev set error is 10%. Now, the error due to incorrect labels makes up for 0.6% of the total 10% error. There is the 9.4% worth of error that you should be focusing on rather than fixing the incorrect labels. Lets say, by working on other errors, you have decreases the dev set error down to 2%. Now, the same 0.6% worth of errors, makes up for 30% of the total dev error you are getting. So now it is more worthwhile for you to fix up the incorrect labels in your dev set. Also, remember that the main purpose of the dev set is to help you choose between multiple models, in this case 2 classifiers, so if the dev set is untrustworthy due to the mislabeled examples, then it won't reliably tell you which classifier is better.

if you decide to go into your dev set and manually re-examine the labels and try to fix up some of the labels, here are a few additional guidelines or principles to consider.

* First, I would encourage you to apply whatever process you apply to both your dev and test sets at the same time. We've talk previously about why you want your dev and test sets to come from the same distribution. So if you're going in to fix something on the dev set, I would apply the same process to the test set to make sure that they continue to come from the same distribution.

* Second, you should consider examining examples your algorithm got right as well as ones it got wrong. It is easy to look at the examples your algorithm got wrong and just see if any of those need to be fixed. But it's possible that there are some examples that you haven't got right, that should also be fixed. And if you only fix ones that your algorithms got wrong, you end up with more bias estimates of the error of your algorithm.

* Finally, if you go into a dev and test data to correct some of the labels there, you may or may not decide to go and apply the same process for the training set. Remember we said that at the start that it's actually less important to correct the labels in your training set. And it's quite possible you decide to just correct the labels in your dev and test set which are also often smaller than a training set and you might not invest all that extra effort needed to correct the labels in a much larger training set, which is actually okay.