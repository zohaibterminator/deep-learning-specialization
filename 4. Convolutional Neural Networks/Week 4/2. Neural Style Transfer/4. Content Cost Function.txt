The cost function of the neural style transfer algorithm had a content cost component and a style cost component. We will now define the content cost component.

Let's say that you use hidden layer 'l' to compute the content cost. If l is a very small number, if you use hidden layer one, then it will really force your generated image to have pixel values very similar to your content image. Whereas, if you use a very deep layer, then it's just asking, "Well, if there is a dog in your content image, then make sure there is a dog somewhere in your generated image." So in practice, layer 'l' chosen somewhere in between. It's neither too shallow nor too deep in the neural network. Then, you can use a pre-trained ConvNet, for example a VGG network. And now, you want to measure, given a content image and given a generated image, how similar are they in content. For that, you have a^[l](C) and a^[l](G), which are the activations of layer 'l' for the images C and G. If, both the activations are similar, than both images have similar content. So, basically we define J_content(C, G) as the squared norm of the element-wise differences of the activations:

J_content(C, G) = ||a^[l](C) - a^[l](G)||^2

And you could have a normalization constant in front or not, so it's just 1/2 or something else. It doesn't really matter since this can be adjusted as well by this hyperparameter Î± in the overall cost function. Just to be clear we are using the norm notation as if both of the activations have been unrolled into vectors. And so, when later you perform gradient descent on J(G) to try to find a value of G, so that the overall cost is low, this will incentivize the algorithm to find an image G, so that the hidden layer activations of G are similar to what you got for the content image.