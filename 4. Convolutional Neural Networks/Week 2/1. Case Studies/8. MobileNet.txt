We will now learn about MobileNets, which is another foundational convolutional neural network architecture used for computer vision. Using MobileNets will allow you to build and deploy neural networks that work even in low compute environment, such as a mobile phone.

If we take an example of a normal convolution, the computational cost of a convolution operation of a 6x6x3 sized image and 5 filters of 3x3x3 size resulting in a 4x4x5 image is 2160. Now we will see how depthwise-seperable convolution operation of 6x6x3 image resulting in the same 4x4x5 matrix will work.

In contrast to the normal convolution which you just saw, the depthwise separable convolution has two steps. You're going to first use a depthwise convolution, followed by a pointwise convolution. It is these two steps which together make up this depthwise separable convolution. Lets see how the depthwise convolution step works, which is the step 1 of the depthwise separable convolution operation. So, we have the same image of size 6x6x3, and we will have 3x3 filters, not 3x3x3 filters to match the number of channels of the image. Instead, the number of channels will match the number of filters, so, in this case, the number of filters will be 3, and each of those filters will convolve with a seperate channel. The output of this step will be 4x4x3, where the number of channels of the output will be the same as the number of channels of the input. To calculate the computational cost of this operation, we know that to generate each of the 16 values of a channel, there were 9 multiplications (3x3 filters). And this computation was the same for each channel. So, the computational cost will be 432 multiplications (no. of filters params (3x3) x # no. of filter positions (4x4) x no. of filters (3)). This 4x4x3 matrix, which is the resultant matrix of the depthwise convolution operation, is an intermediate value. Now, we will apply pointwise convolution operation on this intermediate value, which is the second step of the depthwise-separable convolution operation.

In the pointwise convolution operation, we will take the intermediate value, the resultant matrix of the depthwise convolution operation, and convolve it with 1x1xN_c filters. Since, our input is of 4x4x3 size, we will convolve it with a 1x1x3 sized filter. We can use multiple filters in this step, so we decide to go with 5 filters. This results in a 4x4x5 output. To computational cost of this whole operation will be 240 multiplications.

If we summarize the comparison of the cost of the normal convolution operation and depthwise-separable convolution operation, we can see that the cost of depthwise-seperable convolution is smaller compared to normal convolution operation, as depthwise-seperable convolution operation costed us 672 multiplications compared to 2160 multiplications cost of the normal convolution operation. This means the normal convolution operation is 31% more computationally expensive compared to depthwise-separable convolution operation in this example.

The authors of the MobileNet's paper showed that in general, the ratio of the cost of the depthwise separable convolution compared to the normal convolution turns out to be equal to 1/N_c' (number of filters) + 1/f^2 (size of filters) in the general case. In our case, this was 1/5 + 1/3^2 or 1/9, which is 0.31. In a more typical neural network example, N_c' will be much bigger. So may be, say, 1/512. If you have 512 channels in your output plus 1/3^2, this would be a fairly typical parameters of a neural network. So, very roughly, the depthwise separable convolution may be about roughly 10 times cheaper in computational costs.