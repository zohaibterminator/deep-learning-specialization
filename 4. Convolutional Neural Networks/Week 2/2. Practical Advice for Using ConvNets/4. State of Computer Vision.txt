Deep learning has been successfully applied to computer vision, natural language processing, speech recognition, online advertising, logistics, many other problems. There are a few things that are unique about the application of deep learning to computer vision, about the status of computer vision. We will learn some of the observations about deep learning for computer vision which will help you better navigate the literature, and the set of ideas out there, and how you build these systems yourself for computer vision.

You can think of most machine learning problems as falling somewhere on the spectrum between where you have relatively little data to where you have lots of data. So for example, I think that today we have a decent amount of data for speech recognition and it's relative to the complexity of the problem. And even though there are reasonably large data sets today for image recognition or image classification, because image recognition is just a complicated problem. It feels like even though the online data sets are quite big like over a million images, feels like we still wish we had more data. And there are some problems like object detection where we have even less data, which fall towards the "little data" end of the spectrum, because of the cost of getting the bounding boxes is just more expensive to label the objects and the bounding boxes. So, we tend to have less data for object detection than for image recognition.

As a result, if you look across a broad spectrum of machine learning problems, you see on average that when you have a lot of data you tend to find people getting away with using simpler algorithms as well as less hand-engineering. So, there's just less needing to carefully design features for the problem. Whereas, in contrast when you don't have that much data then on average you see people engaging in more hand-engineering. I think when you don't have much data then hand-engineering is actually the best way to get good performance.

So, when I look at machine learning applications I think usually we have the learning algorithm has two sources of knowledge. One source of knowledge is the labeled data, really the (x,y) pairs you use for supervised learning. And the second source of knowledge is the hand-engineering. And there are lots of ways to hand-engineer a system. It can be from carefully hand designing the features, to carefully hand designing the network architectures to maybe other components of your system. And so when you don't have much labeled data you just have to call more on hand-engineering. And so I think computer vision is trying to learn a really complex function. And it often feels like we don't have enough data for computer vision. Even though data sets are getting bigger and bigger, often we just don't have as much data as we need. And this is why this data computer vision historically and even today has relied more on hand-engineering. And I think this is also why that either computer vision has developed rather complex network architectures, is because in the absence of more data the way to get good performance is to spend more time architecting, or fooling around with the network architecture. And in fact, because you usually have smaller object detection data sets than image recognition data sets, when we talk about object detection that is task like this next week. You see that the algorithms become even more complex and has even more specialized components. Fortunately, one thing that helps a lot when you have little data is transfer learning. And I would say for the example from the previous slide of the tigger, misty, neither detection problem you have so little data that transfer learning will help a lot.

If you look at the computer vision literature, and look at the sort of ideas out there, you also find that people are really enthusiastic and are really into doing well on standardized benchmark datasets and on winning competitions. And for computer vision researchers if you do well and the benchmark it is easier to get the paper published. And the positive side of this is that, it helps the whole community figure out what are the most effective algorithms. But you also see in the papers people do things that allow you to do well on a benchmark, but that you wouldn't really use in a production or a system that you deploy in an actual application. So, here are a few tips on doing well on benchmarks.

One is ensembling. And what that means is, after you've figured out what neural network you want, train several neural networks independently and average their outputs. So, initialize say 3, or 5, or 7 neural networks randomly and train up all of these neural networks, and then average their outputs. And by the way. it is important to average their outputs y hats. Don't average their weights that won't work. And this will cause you to do maybe 1% better, or 2% better, which really help win a competition. But because ensembling means that to test on each image, you might need to run an image through anywhere from say 3 to 15 different networks quite typical. This slows down your running time by a factor of 3 to 15, or sometimes even more. And so ensembling is one of those tips that people use doing well in benchmarks and for winning competitions. But that I think is almost never use in production to serve actual customers. One of the big problems of ensembling is that you need to keep all these different networks around. And so that just takes up a lot more computer memory.

Another thing you see in papers that really helps on benchmarks, is multi-crop at test time. So, what I mean by that is you've seen how you can do data augmentation. And multi-crop is a form of applying data augmentation to your test image as well. So for example, let's see a cat image and just copy it four times including mirrored versions. Then you take the first image, take the central crop, run it through the classifier, take the next image, and take the crops of that of it's four corners, and run each of them through the classifier, then take the next image, take the central crop, run it through the classifier, then on the final image take the four corners crop and run them each through the classifier and then average the results. The total number of crops you will do is 10, which is why this is called the 10-crop technique. So, if you have the computational budget you could do this. If you want to use this technique in production, maybe you don't need as many as 10-crops, you can use a few crops. For multi-crop I guess at least you keep just one network around, compared to ensembling, so it doesn't suck up as much memory, but it still slows down your run time quite a bit.

Because a lot of the computer vision problems are in the small data regime, others have done a lot of hand-engineering of the network architectures. And a neural network that works well on one vision problem often may be surprisingly, would work on other vision problems as well. So, to build a practical system often you do well starting off with someone else's neural network architecture. And you should use an open source implementation if possible, because the open source implementation might have figured out all the finicky details like the learning rate, decay scheduler, and other hyper parameters. And finally someone else may have spent weeks training a model on half a dozen GPUs and on over a million images. And so by using someone else's pretrained model and fine tuning on your data set, you can often get going much faster on an application. But of course if you have the compute resources and the inclination, don't let me stop you from training your own networks from scratch. And in fact if you want to invent your own computer vision algorithm, that's what you might have to do.