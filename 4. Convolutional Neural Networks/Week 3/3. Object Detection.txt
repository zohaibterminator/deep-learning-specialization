We will know see how object detection is performed using a ConvNet with an algorithm called Sliding Windows Detection algorithm.

Let's say you want to build a car detection algorithm. Here's what you can do. You can first create a label training set, so x and y with closely cropped examples of cars. And for our purposes in this training set, you can start off with the one with the car closely cropped images. So, you can take a picture and crop out and just cut out anything else that's not part of a car. So you end up with the car centered in pretty much the entire image. Given this label training set, you can then train a ConvNet that inputs an image, like one of these closely cropped images. And then the job of the ConvNet is to output y, zero or one, is there a car or not. Once you've trained up this ConvNet you can then use it in Sliding Windows Detection.

So the way you do that is, if you have a test image, you would input into this ConvNet a small rectangular region, and have a ConvNet make a prediction whether the small picture is a car or not. Then, you slide the region over by some stride, then input that region into the ConvNet for a prediction, and so on until you've slid the window across every position in the image. Now, having done this once through the image, you then repeat it, but now use a larger window. So, resize the original region into whatever larger input size the ConvNet is expecting, and feed that to the ConvNet and have it output zero or one. And then slide the window over again using some stride and so on. And you run that throughout your entire image until you get to the end. And then you might do the third time using even larger windows and so on. And the hope is that if you do this, then so long as there's a car somewhere in the image that there will be a window where hopefully the ConvNet will have output one for that input region. So then you detect that there is a car there.

So this algorithm is called Sliding Windows Detection because you take these windows, these square boxes, and slide them across the entire image and classify every square region with some stride as containing a car or not.

Now there's a huge disadvantage of Sliding Windows Detection, which is the computational cost. Because you're cropping out so many different square regions in the image and running each of them independently through a ConvNet. And if you use a very coarse stride, a very big stride, then that will reduce the number of windows you need to pass through the ConvNet, but that courser granularity may hurt performance. Whereas if you use a very fine granularity or a very small stride, then the huge number of all the little regions you're passing through the ConvNet means that means there is a very high computational cost.

So, before the rise of Neural Networks people used to use much simpler classifiers like a simple linear classifier over hand engineer features in order to perform object detection. And in that era because each classifier was relatively cheap to compute, it was just a linear function, Sliding Windows Detection ran okay. It was not a bad method, but with ConvNet now running a single classification task is much more expensive and sliding windows this way is infeasibily slow. And unless you use a very fine granularity or a very small stride, you end up not able to localize the objects that accurately within the image as well.

Fortunately however, this problem of computational cost has a pretty good solution. In particular, the Sliding Windows Object Detector can be implemented convolutionally or much more efficiently.