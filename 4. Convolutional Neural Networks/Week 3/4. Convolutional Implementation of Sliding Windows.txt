Previously, we learned about the sliding windows object detection algorithm using a ConvNet but we saw that it was too slow. Now, we will see how we can implement this algorithm convolutionally. To build up towards the convolutional implementation of sliding windows let's first see how you can turn fully connected layers in neural network into convolutional layers.

So let's say that your object detection algorithm inputs 14x14x3 images. This is quite small but just for illustrative purposes, and let's say it then uses 16 5x5 filters to map the image from 14x14x3 to 10x10x16. And then does a 2x2 max pooling to reduce it to 5x5x16. Then we have 2 FC/Dense layers with 400 neurons each and then finally a 4 unit softmax layer.

Now, if we want to implement the FC layers using Convolutional Layer, what we will do is use after the pooling layer, we will use a Conv Layer with 400 5x5 filters. So, if you take 5x5x16 image and convolve with with 400 5x5x16 filters, you will get 1x1x400 volume. So, instead of viewing the FC layer as 400 nodes, we will view it as a 1x1x400 volume. Mathematically, this is the same as a fully connected layer because each of these 400 nodes has a filter of dimension 5x5x16. So each of those 400 values is some arbitrary linear function of these 5x5x16 activations from the previous layer. Now, for implementing the 2nd FC layer, we will use another Conv layer with 400 1x1 filters. This will then yield a 1x1x400 volume. Then, for the softmax layer, we will use another Conv layer of 4 filters of 1x1 convolution.

Now, we will look at implemetation of Sliding Window detection using Convolution, which is based on the OverFeat paper. We will take the same images of size 14x14x3. We will use the same ConvNet, in which we replaced the FC layers with the Conv layers. The ConvNet outputs a 1x1x4 volume, as discussed earlier. Let's say you have a test set of 16x16x3. Now, we will use the Sliding Window detection method and take 14x14x3 windows, and pass them through our trained convolutional classifier. After passing a window through the classifier, we will move the window using a fixed stride, and then pass the second window and so on. 4 convolutional passes will be done for our image of 16x16x3 size. But it turns out a lot of this computation done by these four convnets is highly duplicative.

So what the convolutional implementation of sliding windows does is it allows these four passes in the convnet to share a lot of computation. If we pass the 16x16x3 image directly though the convnet, we will get a 2x2x4 volume, instead of a 1x1x4 volume. It turns out that the top left most block of 1x1x4 size of the 2x2x4 volume represents the results for the top left 14x14x3 sized region of the 16x16x3 image. So, instead of passing the regions independently, we can just perform 1 pass, and due to the overlapping computations, we will get the results of all 4 passes in 1 pass.

Now, this algorithm still has one weakness, which is the position of the bounding boxes is not going to be too accurate. We will see how we can fix that next.