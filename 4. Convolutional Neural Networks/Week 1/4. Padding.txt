In order to build deep neural networks one modification to the basic convolutional operation that you need to really use is padding.

We saw previously, that if you take a 6x6 image, and convolve it with a 3x3 filter, you get a 4x4 matrix. Because there are 4x4 possible positions for the 3x3 filter to fit in your 6x6 image. The maths of this is that if you have a nxn image, and you convolve it with a fxf filter, the output matrix will be a (n-f+1)x(n-f+1) matrix. One, downsides of this is that when you apply the convolutional operation, your outputs shrinks, and you can only do this a few times before your image starts to get really small. Another downside of this is that the corner pixels, the ones at the top left, bottom left, top right and bottom right are used only once to calculate the output. In contrast to that, if you pick a pixel in the middle, there are a lot of 3x3 regions that will overlap with that pixel and so, is as if pixels on the corners or on the edges are use much less in the output. So you're throwing away a lot of the information near the edge of the image.

To solve both of these problems, you can pad the image before applying the convolutional operation. Lets say you pad the image by 1 pixel, so now instead of 6x6 image, you now have an 8x8 image. So, now if you convolve the image with a 3x3 filter, you get a 6x6 resultant matrix, meaning you preserved the original size of 6x6. By convention, when you pad, you pad the image with zeros, and if p is the padding amount, then in this case p is 1, so the resultant image after the convolution operation will be of (n + 2*p - f + 1)x(n + 2*p - f + 1) size, which in our case will be 6x6.

In terms of how much to pad, it turns out there two common choices that are called, Valid convolutions and Same convolutions. Valid convolutions basically mean that there is no padding. So, if you have a nxn image and you convolve it with a fxf filter, you will get a (n-f+1)x(n-f+1) image. The other most common choice of padding is called Same convolutions, which means that you pad so that the resultant matrix is of the same size as the input matrix. We know that the resultant matrix is of the (n + 2*p - f + 1)x(n + 2*p - f + 1) size if we are applying padding. So, if we want the (n + 2*p - f + 1) to be equal to n, then p should be equal to (f-1)/2. This ensures that the output size is the same as the input size. Also by convention in CV, f is almost always odd. The reason for that would be that if f was even, then you would need asymmetric padding. So only if f is odd that this type of same convolution gives a natural padding region, had the same dimension all around rather than pad more on the left and pad less on the right, or something that asymmetric. And then second, when you have an odd dimension filter, such as 3x3 or 5x5, then it has a central position and sometimes in computer vision its nice to have a distinguisher, it's nice to have a pixel, you can call the central pixel so you can talk about the position of the filter.